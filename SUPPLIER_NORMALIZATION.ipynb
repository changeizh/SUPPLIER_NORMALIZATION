{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "import pandas as pd\n",
    "from unidecode  import unidecode\n",
    "import pyodbc\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing_special_characters(txt):\n",
    "    seps = [' ',';',':','.','`','~',',','*','#','@','|','\\\\','-','_','?','%','!','^','(',')','[',']','{','}','$','=','+','\"','<','>',\"'\",' AND ', ' and ']\n",
    "    default_sep = seps[0]\n",
    "    txt = str(txt)\n",
    "    for sep in seps[1:]:\n",
    "        if sep == \" AND \" or sep == \" and \":\n",
    "            txt = txt.upper()\n",
    "            txt = txt.replace(sep, ' & ')\n",
    "        else:\n",
    "            txt = txt.upper()\n",
    "            txt = txt.replace(sep, default_sep)\n",
    "    try :\n",
    "        list(map(int,txt.split()))\n",
    "        txt = 'NUMBERS'\n",
    "    except:\n",
    "        pass\n",
    "    txt = re.sub(' +', ' ', txt)\n",
    "    temp_list = [i.strip() for i in txt.split(default_sep)]\n",
    "    temp_list = [i for i in temp_list if i]\n",
    "    return \" \".join(temp_list)\n",
    "\n",
    "\n",
    "###########################################################\n",
    "\n",
    "punctuation = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "class fingerprinter(object):\n",
    "    \n",
    "    # __init__function\n",
    "    \n",
    "    def __init__(self, string):\n",
    "        self.string = self._preprocess(string)\n",
    "        \n",
    "    \n",
    "    # strip leading, trailing spaces and to lower case\n",
    "    def _preprocess(self, string):\n",
    "        return punctuation.sub('',string.strip().lower())\n",
    "    \n",
    "        \n",
    "    def _latinize(self, string):\n",
    "        return unidecode(string)\n",
    "#         return unidecode(string.decode('utf-8'))\n",
    "    \n",
    "    def _unique_preserve_order(self,seq):\n",
    "        seen = set()\n",
    "        seen_add = seen.add\n",
    "        return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "    \n",
    "    #-####################################################\n",
    "    def get_fingerprint(self):\n",
    "        return self._latinize(' '.join(self._unique_preserve_order(sorted(self.string.split()))))\n",
    "    \n",
    "    ######################################################\n",
    "    def get_ngram_fingerprint(self, n=1):\n",
    "        return self._latinize(''.join(self._unique_preserve_order(sorted([self.string[i:i + n] for i in range(len(self.string) - n +1)]))))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server Native Client 11.0}; Server=192.168.1.47; uid=seair; pwd=se@ir1234; Database = tempEXIM; Trusted_Connection = No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Indo_buyer_tbuuuuuu-xlsx.xlsx'\n",
    "# df = pd.read_sql(\"\"\"select distinct BUYER_NAME as SUPPLIER_NAME from DB_Indonesia..Indonesia_Exp2019 where LEN(BUYER_NAME)>10 union \n",
    "# select distinct BUYER_NAME as SUPPLIER_NAME from DB_Indonesia..Indonesia_Exp2020 where LEN(BUYER_NAME)>10  \"\"\",conn)\n",
    "df = pd.read_excel(filename)\n",
    "\n",
    "#preprocess the column\n",
    "df['Clean'] = df['SUPPLIER_NAME'].apply(cleansing_special_characters)\n",
    "\n",
    "# step 1 cleanining\n",
    "###########################################################################################\n",
    "\n",
    "# ##for n_gram fingerprint algorithm\n",
    "###########################################################################################\n",
    "\n",
    "df['n_gram_fingerprint_n2'] = df['Clean'].apply(lambda x : fingerprinter(x.replace(\" \",\"\")).get_ngram_fingerprint(n=2))\n",
    "\n",
    "## generate tag_id for every unique generated n_gram_fingerprint\n",
    "d = defaultdict(lambda: len(d))\n",
    "df['tag_idn']=[d[x] for x in df['n_gram_fingerprint_n2']]\n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "#drop n_gram column\n",
    "df.drop(columns=['n_gram_fingerprint_n2'], inplace=True)\n",
    "\n",
    "# make copy to create group of tag_id\n",
    "df1 = df[['SUPPLIER_NAME','tag_idn']]\n",
    "\n",
    "\n",
    "# drop SUPPLIER_NAME column , we have tag_id's now\n",
    "df.drop(columns=['SUPPLIER_NAME'], inplace=True)\n",
    "\n",
    "# group df with tag_id with selecting minimum \n",
    "#group = df.groupby('tag_id').min().reset_index()\n",
    "group = df.loc[df[\"Clean\"].str.len().groupby(df[\"tag_idn\"]).idxmax()]\n",
    "\n",
    "# join both the data frames group(unique) and main data\n",
    "df_merge = pd.merge(df1,group, on=['tag_idn'])\n",
    "\n",
    "# sterp 2 cleaning\n",
    "##########################################################################################\n",
    "##for fingerprint algorithm\n",
    "###########################################################################################\n",
    "df_merge['fingerprint'] = df_merge['Clean'].apply(lambda x : fingerprinter(x).get_fingerprint())\n",
    "\n",
    "## generate tag_id for every unique generated n_gram_fingerprint\n",
    "d = defaultdict(lambda: len(d))\n",
    "df_merge['tag_idf']=[d[x] for x in df_merge['fingerprint']]\n",
    "                                      \n",
    "# drop fingerprint column\n",
    "df_merge.drop(columns=['fingerprint'], inplace=True)\n",
    "                                                  \n",
    "df2 = df_merge[['tag_idf','Clean']]\n",
    "group1 = df2.loc[df2[\"Clean\"].str.len().groupby(df2[\"tag_idf\"]).idxmax()]\n",
    "df_merge1 = pd.merge(df_merge,group1, on=['tag_idf'])\n",
    "df_merge1.index.name = 'Serial No.'\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "# rearrange columns\n",
    "# # output excel file\n",
    "df_merge1.to_excel(filename.strip('.xlsx')+'_Cleaned' +\".xlsx\")\n",
    "# print('File {} Generated'.format(filename.strip('.xlsx')+'_Cleaned'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
