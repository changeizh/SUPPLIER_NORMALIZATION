{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "import pandas as pd\n",
    "from unidecode  import unidecode\n",
    "import pyodbc\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing_special_characters(txt):\n",
    "    seps = [' ',';',':','.','`','~',',','*','#','@','|','\\\\','-','_','?','%','!','^','(',')','[',']','{','}','$','=','+','\"','<','>',\"'\",' AND ', ' and ']\n",
    "    default_sep = seps[0]\n",
    "    txt = str(txt)\n",
    "    for sep in seps[1:]:\n",
    "        if sep == \" AND \" or sep == \" and \":\n",
    "            txt = txt.upper()\n",
    "            txt = txt.replace(sep, ' & ')\n",
    "        else:\n",
    "            txt = txt.upper()\n",
    "            txt = txt.replace(sep, default_sep)\n",
    "    try :\n",
    "        list(map(int,txt.split()))\n",
    "        txt = 'NUMBERS'\n",
    "    except:\n",
    "        pass\n",
    "    txt = re.sub(' +', ' ', txt)\n",
    "    temp_list = [i.strip() for i in txt.split(default_sep)]\n",
    "    temp_list = [i for i in temp_list if i]\n",
    "    return \" \".join(temp_list)\n",
    "\n",
    "\n",
    "###########################################################\n",
    "\n",
    "punctuation = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "class fingerprinter(object):\n",
    "    \n",
    "    # __init__function\n",
    "    \n",
    "    def __init__(self, string):\n",
    "        self.string = self._preprocess(string)\n",
    "        \n",
    "    \n",
    "    # strip leading, trailing spaces and to lower case\n",
    "    def _preprocess(self, string):\n",
    "        return punctuation.sub('',string.strip().lower())\n",
    "    \n",
    "        \n",
    "    def _latinize(self, string):\n",
    "        return unidecode(string)\n",
    "#         return unidecode(string.decode('utf-8'))\n",
    "    \n",
    "    def _unique_preserve_order(self,seq):\n",
    "        seen = set()\n",
    "        seen_add = seen.add\n",
    "        return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "    \n",
    "    #-####################################################\n",
    "    def get_fingerprint(self):\n",
    "        return self._latinize(' '.join(self._unique_preserve_order(sorted(self.string.split()))))\n",
    "    \n",
    "    ######################################################\n",
    "    def get_ngram_fingerprint(self, n=1):\n",
    "        return self._latinize(''.join(self._unique_preserve_order(sorted([self.string[i:i + n] for i in range(len(self.string) - n +1)]))))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server Native Client 11.0}; Server=192.168.1.47; uid=seair; pwd=se@ir1234; Database = tempEXIM; Trusted_Connection = No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SUPPLIER_NAME'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2898\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2899\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'SUPPLIER_NAME'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c4fe0c08343a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#preprocess the column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Clean'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SUPPLIER_NAME'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleansing_special_characters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# step 1 cleanining\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2904\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2905\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2906\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2907\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2898\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2900\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2902\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'SUPPLIER_NAME'"
     ]
    }
   ],
   "source": [
    "filename = 'C:/Users/Manish/Desktop/PIN/Add_City_pin_tbffffffffffff.xlsx'\n",
    "# df = pd.read_sql(\"\"\"select distinct BUYER_NAME as SUPPLIER_NAME from DB_Indonesia..Indonesia_Exp2019 where LEN(BUYER_NAME)>10 union \n",
    "# select distinct BUYER_NAME as SUPPLIER_NAME from DB_Indonesia..Indonesia_Exp2020 where LEN(BUYER_NAME)>10  \"\"\",conn)\n",
    "df = pd.read_excel(filename)\n",
    "\n",
    "#preprocess the column\n",
    "df['Clean'] = df['SUPPLIER_NAME'].apply(cleansing_special_characters)\n",
    "\n",
    "# step 1 cleanining\n",
    "###########################################################################################\n",
    "\n",
    "# ##for n_gram fingerprint algorithm\n",
    "###########################################################################################\n",
    "\n",
    "df['n_gram_fingerprint_n2'] = df['Clean'].apply(lambda x : fingerprinter(x.replace(\" \",\"\")).get_ngram_fingerprint(n=2))\n",
    "\n",
    "## generate tag_id for every unique generated n_gram_fingerprint\n",
    "d = defaultdict(lambda: len(d))\n",
    "df['tag_idn']=[d[x] for x in df['n_gram_fingerprint_n2']]\n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "#drop n_gram column\n",
    "df.drop(columns=['n_gram_fingerprint_n2'], inplace=True)\n",
    "\n",
    "# make copy to create group of tag_id\n",
    "df1 = df[['SUPPLIER_NAME','tag_idn']]\n",
    "\n",
    "\n",
    "# drop SUPPLIER_NAME column , we have tag_id's now\n",
    "df.drop(columns=['SUPPLIER_NAME'], inplace=True)\n",
    "\n",
    "# group df with tag_id with selecting minimum \n",
    "#group = df.groupby('tag_id').min().reset_index()\n",
    "group = df.loc[df[\"Clean\"].str.len().groupby(df[\"tag_idn\"]).idxmax()]\n",
    "\n",
    "# join both the data frames group(unique) and main data\n",
    "df_merge = pd.merge(df1,group, on=['tag_idn'])\n",
    "\n",
    "# sterp 2 cleaning\n",
    "##########################################################################################\n",
    "##for fingerprint algorithm\n",
    "###########################################################################################\n",
    "df_merge['fingerprint'] = df_merge['Clean'].apply(lambda x : fingerprinter(x).get_fingerprint())\n",
    "\n",
    "## generate tag_id for every unique generated n_gram_fingerprint\n",
    "d = defaultdict(lambda: len(d))\n",
    "df_merge['tag_idf']=[d[x] for x in df_merge['fingerprint']]\n",
    "                                      \n",
    "# drop fingerprint column\n",
    "df_merge.drop(columns=['fingerprint'], inplace=True)\n",
    "                                                  \n",
    "df2 = df_merge[['tag_idf','Clean']]\n",
    "group1 = df2.loc[df2[\"Clean\"].str.len().groupby(df2[\"tag_idf\"]).idxmax()]\n",
    "df_merge1 = pd.merge(df_merge,group1, on=['tag_idf'])\n",
    "df_merge1.index.name = 'Serial No.'\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "# rearrange columns\n",
    "# # output excel file\n",
    "df_merge1.to_excel(filename.strip('.xlsx')+'_Cleaned' +\".xlsx\")\n",
    "# print('File {} Generated'.format(filename.strip('.xlsx')+'_Cleaned'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'C:/Users/Manish/Desktop/PIN/Add_City_pin_tbffffffffffff.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean'] = df['addres'].apply(cleansing_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(filename.strip('.xlsx')+'_Cleaned' +\".xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
